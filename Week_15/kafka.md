压缩算法
推荐压缩算法有很多推荐使用zstd或者lz4，lz4吞吐量高，zstd压缩比例高，工具场景来选择
无消息丢失
生产者与kafka通信之间
producer.send回调函数
ack=all所有在同步副本确认提交才提交成功
retry>0保证出错后重试，幂等由broker端自己保证
禁止同步落后的的副本竞选leader
设置副本数>=3
最少的在同步副本必须大于1
消费端开启手动提交位移
拦截器
应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景
实例化时，配置文件里加入拦截器的全类名
生产者拦截器：继承ProducerInterceptor，实现onsend和onAcknowledgement
消费者拦截器：继承ConsumerInterceptor，实现onConsume和onCommit
tcp的创建时机
生产者端：创建实例的时候，先建立与配置项里面的broker.server的TCP,获取到broker的元数据后建立所有的TCP，元数据同步是定时的，如果在刷新之前请求新的broker则立即建立新TCP，关闭连接可以手动close，也可以配置最大连接时长
消费者端：在调用poll方法是才开启TCP连接，第一次连接寻找协调者，第二次连接连接到协调者获取数据brocker，第三次连接到消费brocker
消息一致性
最多一次，至少一次，精确一次
kafka可以做到精确一次，通过producer端设置幂等参数为true（只保证单个partition幂等），结合事务开启（读已提交）initTransaction、beginTransaction、commitTransaction 和 abortTransaction
消费端同时需要开启read_committed，开启手动提交位移
Rebalance
导致重平衡是有由于订阅的topic数量变化、topic的分区发生变化或者消费者数量发生变化
90%的场景是消费者的数量变化导致的，手动添加了消费者，消费者以外被踢出（消费时间长导致被误判，网络波动导致心跳未发送到），频繁的fullGC。解决方法：适当增加消费时长，心跳时长和心跳次数。
多线程消费
同一个消费者组，多个消费者，分别获取消息，分别执行
同一个消费者组，一个消费者获取消息，多个线程处理业务逻辑

高水位
高水位之前都是已提交的数据，数据消费的延迟指标，当前下标到高水位的距离，和当前下标到起始位置的距离。由于是定时删除历史数据，所以到起始位置越来越近是非常严重的一个问题，很有可能导致丢数据。
